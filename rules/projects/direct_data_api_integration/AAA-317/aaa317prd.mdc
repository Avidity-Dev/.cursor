# PRD_018_Phase1_fast_MVP: Veeva CRM API to ADLS Raw Ingest (Simplified)

<!-- Applying rule: general/prd - PRD structure and content -->
<!-- Applying rule: general/documentation - Documentation standards -->

## Table of Contents

- [1. Motivation & Context](#1-motivation--context)
- [2. Project Goals](#2-project-goals)
- [3. Scope](#3-scope)
  - [3.1. In Scope](#31-in-scope)
  - [3.2. Out of Scope](#32-out-of-scope)
- [4. Technical Approach](#4-technical-approach)
  - [4.1. Overview](#41-overview)
  - [4.2. Key Components](#42-key-components)
    - [4.2.1. Veeva API Interaction (`prometheus/veeva/api.py`)](#421-veeva-api-interaction)
    - [4.2.2. Dagster Resources (`prometheus/veeva/resources.py`)](#422-dagster-resources)
    - [4.2.3. Dagster Asset (`prometheus/veeva/assets.py`)](#423-dagster-asset)
    - [4.2.4. HTTP Client Choice: `httpx`](#424-httpx)
  - [4.3. Secrets Management](#43-secrets-management)
  - [4.4. ADLS Output](#44-adls-output)
- [5. Implementation Tasks](#5-implementation-tasks)
- [6. Success Criteria](#6-success-criteria)
- [7. Key Dependencies & Assumptions](#7-key-dependencies--assumptions)
- [8. Future Considerations (Post-MVP)](#8-future-considerations)
- [9. Documentation Requirements](#9-documentation-requirements)

## 1. Motivation & Context

This document outlines a streamlined **Fast MVP (Minimum Viable Product)** approach for Phase 1 of the Veeva CRM data integration. The primary objective is to quickly establish a pipeline that retrieves raw data export files (specifically full, single-part `.tar.gz` archives) from the Veeva Direct Data API and lands them into Azure Data Lake Storage (ADLS).

This simplified approach defers more complex features like multi-part file handling, incremental loads, and in-pipeline transformations to accelerate the initial delivery of Veeva data to ADLS. This aligns with the immediate business need to access raw Veeva CRM data in Azure.

This PRD supersedes the direct implementation of individual Linear tasks AAA-317, AAA-318, and AAA-319 for this initial MVP, by defining a single, focused effort to achieve the core data landing. The detailed functionality described in those Linear tickets will be revisited for subsequent phases. The approach documented here prioritizes a custom `httpx`-based API client for speed of initial implementation; a `dlt`-native approach using `dlt.sources.rest_api_source` is documented separately in `PRD_018_dlt_ingestion.md` for future consideration.

Reference: For more details on the Veeva Direct Data API, see `@veeva-direct-data-api.mdc`.

## 2. Project Goals

*   Rapidly implement a functional data pipeline to extract full `.tar.gz` export files from Veeva Direct Data API.
*   Securely upload these raw export files to a designated location in Azure Data Lake Storage (ADLS).
*   Establish a foundational Dagster asset that can be evolved in future phases.
*   Prioritize simplicity and speed of delivery for this MVP.

## 3. Scope

### 3.1. In Scope

*   **Veeva API Interaction**:
    *   Authenticate with the Veeva Direct Data API using provided credentials (`VAULT_USERNAME`, `VAULT_PASSWORD`, `VAULT_DOMAIN` from `.env`).
    *   List available "full" data export files.
    *   Download a single, complete, full export file (`.tar.gz` format). For this MVP, we will assume files are single-part.
*   **ADLS Upload**:
    *   Upload the downloaded `.tar.gz` file to a specified ADLS container and path.
    *   Utilize the existing `AzureBlobStore` client (`prometheus/azure/blob.py`) and the `AZURE_BLOB_STORE_CONNECTION_STRING` from `.env`.
*   **Dagster Orchestration**:
    *   Create a single Dagster asset to manage the download and upload process.
    *   Define appropriate Dagster resources for Veeva API credentials and ADLS configuration.
*   **Focus**: Full loads of single-part `.tar.gz` files only.
*   **Error Handling**: Basic error handling for API calls and ADLS uploads.
*   **Logging**: Basic logging of asset execution steps and outcomes.

### 3.2. Out of Scope

*   **Incremental Loads**: Processing of Veeva incremental export files.
*   **Multi-part File Handling**: Logic to download and concatenate multi-part Veeva export files.
*   **Data Transformation/Unpacking**: No unpacking or transformation of the `.tar.gz` file content within this pipeline. The file will be landed in ADLS in its raw, compressed form. (This is deferred, aligning with the intent of AAA-318 for a later stage).
*   **Advanced Streaming**: While `AzureBlobStore` supports `BinaryIO`, complex streaming optimizations that might delay the MVP are not a primary requirement if simpler download-then-upload is faster to implement (e.g., download to `io.BytesIO` or temporary local file).
*   **Schema Management/Validation**: No schema inference, validation, or management for the contents of the tarball.
*   **Automated Scheduling**: The asset will be manually triggerable via Dagster UI.
*   **Advanced Observability**: Complex monitoring or alerting beyond basic Dagster logs.
*   **`dlt.sources.rest_api_source` Implementation**: This PRD focuses on a custom `httpx` client. The `dlt`-native approach is documented in `PRD_018_dlt_ingestion.md`.

## 4. Technical Approach

### 4.1. Overview

A Dagster asset will orchestrate the process. It will use a custom Veeva API client (built with `httpx`) to download the specified full export file. Once downloaded (e.g., into an in-memory buffer like `io.BytesIO`), the asset will use the existing `AzureBlobStore` utility to upload the file to ADLS. The general API interaction patterns (authenticate, list files, download file by parts/name) are informed by reviewing Veeva's provided API accelerator examples, though our specific implementation choices (Dagster, ADLS, `httpx`) are tailored to this project's stack and MVP goals.

### 4.2. Key Components

#### 4.2.1. Veeva API Interaction (`prometheus/veeva/api.py`)

A new Python module responsible for:
*   **Authentication**: Obtaining a session ID from Veeva using credentials.
*   **File Listing**: Calling the Veeva Direct Data API endpoint to list available "full" export files.
*   **File Download**: Downloading a specified single-part full export `.tar.gz` file. Given the MVP's focus on simplicity and single-part files, this can download the file content into an `io.BytesIO` object.

```python
# Example structure for prometheus/veeva/api.py
import httpx
import io

class VeevaClient:
    def __init__(self, vault_domain: str, session_id: str, api_version: str = "v24.1"): # Default or configurable API version
        self.base_url = f"https://{vault_domain}/api/{api_version}"
        self.session_id = session_id
        self.headers = {
            "Authorization": self.session_id,
            "Accept": "application/json"
        }

    async def list_full_export_files(self) -> list:
        # Logic to call Veeva API (e.g., services/directdata/files) to list 'full_directdata' files.
        # Parameters: extract_type='full_directdata'.
        # Should identify the latest, single-part full file based on response metadata (e.g., 'fileparts': 1).
        # Return list of relevant file metadata dictionaries, or the specific chosen one.
        pass

    async def download_export_file(self, file_download_url: str, original_filename: str) -> (str, io.BytesIO):
        # Logic to download the file content from the absolute file_download_url.
        # The file_download_url comes from the metadata of the selected file.
        # Veeva's API might provide this directly in the 'filepart_details' of the list_files response.
        # Return original_filename and BytesIO stream of the content.
        pass

async def get_veeva_session(vault_domain: str, username: str, password: str, api_version: str = "v24.1") -> str:
    # Logic to authenticate (e.g., POST to /api/{api_version}/auth) and return a session_id.
    # Uses httpx.AsyncClient for the request.
    pass
```

#### 4.2.2. Dagster Resources (`prometheus/veeva/resources.py`)

*   **`VeevaAPIResource(ConfigurableResource)`**:
    *   Configuration: `vault_domain: str`, `vault_username: SecretStr`, `vault_password: SecretStr`, `api_version: str = "v24.1"`.
    *   Provides an initialized `VeevaClient` instance.
*   **`AdlsRawStorageResource(ConfigurableResource)`**:
    *   Configuration: `azure_connection_string: SecretStr`, `container_name: str`, `target_path_prefix: str`.
    *   Provides an initialized `AzureBlobStore` instance.

```python
# Example structure for prometheus/veeva/resources.py
from dagster import ConfigurableResource, SecretStr, Definitions, asset
from prometheus.azure.blob import AzureBlobStore
# Assuming api.py is in the same directory (e.g., from .api import VeevaClient, get_veeva_session)
# This will be: from prometheus.veeva.api import VeevaClient, get_veeva_session

class VeevaAPIResource(ConfigurableResource):
    vault_domain: str
    vault_username: SecretStr
    vault_password: SecretStr
    api_version: str = "v24.1" # Default can be overridden in dagster.yaml

    _client: 'VeevaClient' = None # For caching the client instance

    async def get_client(self) -> 'VeevaClient':
        # AI_NOTE: This is a simplified client caching.
        # In a real scenario, consider how session expiry/renewal would be handled if sessions are short-lived.
        # For Direct Data API, session ID is typically obtained once and used for subsequent calls.
        if self._client is None:
            session_id = await get_veeva_session( # Ensure get_veeva_session is imported
                self.vault_domain,
                self.vault_username.get_secret_value(),
                self.vault_password.get_secret_value(),
                self.api_version
            )
            self._client = VeevaClient( # Ensure VeevaClient is imported
                vault_domain=self.vault_domain, 
                session_id=session_id,
                api_version=self.api_version
            )
        return self._client

class AdlsRawStorageResource(ConfigurableResource):
    azure_connection_string: SecretStr
    container_name: str = "veeva-raw" # Example, can be configured via dagster.yaml
    target_path_prefix: str = "full_exports/" # Example, can be configured via dagster.yaml

    def get_store(self) -> AzureBlobStore:
        return AzureBlobStore(
            connection_string=self.azure_connection_string.get_secret_value(),
            container_name=self.container_name
        )
```

#### 4.2.3. Dagster Asset (`prometheus/veeva/assets.py`)

*   `@asset async def veeva_raw_full_export_to_adls(...)`:
    *   Takes `VeevaAPIResource` and `AdlsRawStorageResource` as inputs using context.
    *   **Logic**:
        1.  Get `VeevaClient` from `VeevaAPIResource`.
        2.  Call client to list available full export files.
        3.  Select the target file (e.g., the most recent single-part full file). Log if no suitable file is found.
        4.  Extract the direct download URL and original filename from the selected file's metadata.
        5.  Log the chosen file.
        6.  Call client to download the file content into an `io.BytesIO` buffer, passing the download URL and original filename.
        7.  Get `AzureBlobStore` instance from `AdlsRawStorageResource`.
        8.  Construct the target blob name (e.g., `f"{adls_resource.target_path_prefix}{original_filename}"`).
        9.  Upload the buffer to ADLS using `store.upload_file()`.
        10. Yield `Output` with metadata (ADLS path, URL, source filename, etc.).

#### 4.2.4. HTTP Client Choice: `httpx`

For making HTTP requests to the Veeva API, this MVP will utilize the `httpx` library instead of the more traditional `requests` library. The primary reasons for this choice are:

*   **Asynchronous Operations**: The `AzureBlobStore` client (in `prometheus/azure/blob.py`), which will be used for uploading the downloaded file to ADLS, is implemented using `async/await`. To integrate smoothly and avoid blocking operations within our Dagster asset, the asset itself will likely be defined as an `async` function.
*   **Native Async Support**: `httpx` provides a `requests`-like API but with native support for `async/await`. This allows for non-blocking I/O operations when calling the Veeva API, fitting naturally within an `async` Dagster asset.
*   **Consistency**: Using `httpx` for API calls maintains an asynchronous pattern throughout the asset's interaction with external services (Veeva API and ADLS).
*   **Alternative (`requests`) Considerations**: While `requests` is robust for synchronous code, using it directly within an `async` asset would require wrapping its calls (e.g., with `asyncio.to_thread`) to prevent blocking the event loop, adding slight complexity.
*   **Modern & Mature**: `httpx` is a modern, well-maintained library (v1.0+) with an API very similar to `requests`, ensuring a gentle learning curve.

This choice supports building a responsive and efficient asset, particularly as interactions with I/O-bound services like APIs and cloud storage are involved.

### 4.3. Secrets Management

*   **Veeva Credentials**: `VAULT_USERNAME`, `VAULT_PASSWORD`, `VAULT_DOMAIN`, `VEEVA_API_VERSION` (optional, with default) will be sourced from `.env` file and loaded into the `VeevaAPIResource` via Dagster's environment variable configuration for resources.
*   **ADLS Credentials**: `AZURE_BLOB_STORE_CONNECTION_STRING` will be sourced from `.env` and loaded into the `AdlsRawStorageResource`.
    *   The `azure_storage_account_name` and `azure_storage_account_key` in `.dlt/secrets.toml` will not be used for this specific MVP asset to maintain simplicity, directly leveraging the existing connection string.

### 4.4. ADLS Output

*   **Container**: To be specified in `AdlsRawStorageResource` (e.g., `veeva-raw`, configurable).
*   **Path Prefix**: To be specified in `AdlsRawStorageResource` (e.g., `full_exports/`, configurable).
*   **Filename**: The original filename from Veeva will be preserved (e.g., `249346-20250716-0000-F.tar.gz`).
*   **Example Full Path**: `veeva-raw/full_exports/249346-20250716-0000-F.tar.gz`

## 5. Implementation Tasks

1.  **Directory and File Setup**:
    *   The `prometheus/veeva/` directory may already exist.
    *   Create or replace the following files within `prometheus/veeva/` based on the designs in this PRD:
        *   `__init__.py` (can be empty or expose assets/resources)
        *   `api.py` (for `VeevaClient` and `get_veeva_session`)
        *   `resources.py` (for `VeevaAPIResource` and `AdlsRawStorageResource`)
        *   `assets.py` (for the `veeva_raw_full_export_to_adls` asset)
2.  **Implement `prometheus/veeva/api.py`**:
    *   Implement `get_veeva_session()` function using `httpx`.
    *   Implement `VeevaClient` class with `list_full_export_files()` and `download_export_file()` methods using `httpx`.
3.  **Implement `prometheus/veeva/resources.py`**:
    *   Implement `VeevaAPIResource` leveraging `api.py`.
    *   Implement `AdlsRawStorageResource`.
4.  **Implement `prometheus/veeva/assets.py`**:
    *   Implement the `veeva_raw_full_export_to_adls` Dagster asset, ensuring it uses the resources correctly.
5.  **Configuration**:
    *   Ensure `.env` file contains `VAULT_USERNAME`, `VAULT_PASSWORD`, `VAULT_DOMAIN`, and `AZURE_BLOB_STORE_CONNECTION_STRING`.
    *   Configure the resources in your Dagster `Definitions` (e.g., in `prometheus/__init__.py` or a dedicated `definitions.py`).
6.  **Testing**:
    *   Unit tests for `api.py` methods (mocking `httpx` calls).
    *   Test the Dagster asset locally, potentially using the pre-downloaded tarball (`~/Downloads/249346-20250507-0000-F.tar.gz`) by temporarily modifying the asset to read from this local file instead of calling the API, to specifically test the ADLS upload part.
    *   End-to-end test by triggering the asset to download from Veeva and upload to a dev ADLS instance.
7.  **Documentation**:
    *   Add docstrings to all new Python code.
    *   Update this PRD as needed during development.
    *   Run `tree` command to update `docs/repository_structure.md` (as per rule `prometheus/tree`).

## 6. Success Criteria

*   The Dagster asset `veeva_raw_full_export_to_adls` successfully executes manually via the Dagster UI or CLI.
*   The asset authenticates with Veeva, lists available full export files, and correctly selects the latest single-part full file.
*   The asset downloads the selected `.tar.gz` file from Veeva into memory (e.g., `io.BytesIO`).
*   The asset uploads the downloaded `.tar.gz` file to the configured ADLS location, preserving the original filename under the specified path prefix.
*   The ADLS path of the uploaded file is logged and available as Dagster `Output` metadata.
*   Basic error conditions (e.g., API auth failure, no suitable file found, ADLS upload failure) are handled gracefully with informative logs and asset failure status.
*   Code is organized into the specified modules (`api.py`, `resources.py`, `assets.py`) within `prometheus/veeva/`.
*   Required secrets are loaded correctly from the `.env` file via Dagster resources.

## 7. Key Dependencies & Assumptions

*   **Veeva Direct Data API Access**:
    *   The API must be enabled for the target Veeva instance.
    *   Valid credentials (`VAULT_USERNAME`, `VAULT_PASSWORD`, `VAULT_DOMAIN`) must be available in `.env`. The API version is also configurable, defaulting to `v24.1`.
    *   Full export files (`.tar.gz`, single-part) must be available via the API. The selection logic will target files marked with `fileparts: 1` (or equivalent in API response).
*   **Azure ADLS Access**:
    *   A valid `AZURE_BLOB_STORE_CONNECTION_STRING` must be available in `.env`.
    *   The specified ADLS container must exist.
*   **Existing Code**:
    *   `prometheus/azure/blob.py` (`AzureBlobStore`) is functional as is.
*   **Development Environment**:
    *   Dagster development environment is set up.
    *   Required Python packages (`httpx`, `dagster`, `python-dotenv`, etc.) are installed.
*   **File Characteristics**:
    *   For this MVP, "full" export files are single-part `.tar.gz` archives.
    *   File sizes are manageable for download into an `io.BytesIO` in-memory buffer.
*   **Reference Materials**:
    *   The pre-downloaded tarball `~/Downloads/249346-20250507-0000-F.tar.gz` and its extracted version in `prometheus/249346-20250507-0000-F/` are representative of the data to be processed and can be used for developing parsing logic if needed, or for mock testing.

## 8. Future Considerations (Post-MVP)

*   Implement handling for multi-part Veeva export files.
*   Add support for incremental loads.
*   Integrate the tarball unpacking logic (aligning with AAA-318).
*   Enhance streaming capabilities for very large files to optimize memory usage further.
*   Implement robust scheduling and monitoring via Dagster.
*   Introduce more sophisticated error handling, retries, and alerting.
*   Parameterize asset for different extract types or configurations more dynamically.
*   Consider session management for Veeva API if sessions are short-lived (current MVP assumes session is valid for the asset run).

## 9. Documentation Requirements

*   **Code Documentation**: All new Python classes, methods, and functions will have clear docstrings explaining their purpose, arguments, and return values, following NumPy style where applicable (as per `prometheus/general/documentation`).
*   **PRD Updates**: This PRD will be considered a living document and updated if significant deviations or clarifications arise during implementation.
*   **Repository Structure**: After new files are created, the `docs/repository_structure.md` will be updated by running the command specified in the `prometheus/tree` rule.
*   **Commit Messages**: Commit messages will be descriptive and reference this PRD (e.g., "feat(veeva): Implement API client for PRD_018_Fast_MVP").
*   **AI-Friendly Annotations**: Where appropriate, `# AI_DOC:`, `# AI_NOTE:`, etc., will be used as per `prometheus/general/documentation`.
