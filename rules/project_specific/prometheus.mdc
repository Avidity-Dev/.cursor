---
description: Prometheus project description
globs: 
alwaysApply: false
---
This project is called prometheus.
Project Code: PRO

Prometheus is a data pipeline utilizing modern data tools, including:

- dlt (Data Load Tool) - Pipelines defined in `prometheus/dlt/` and orchestrated via Dagster.
- dbt (Data Build Tool) - Located in the `transforms/` directory with models organized following dbt best practices (e.g., staging, intermediate, marts).
- Dagster - For orchestration, with assets defined in the main Python package directory `prometheus/`, including orchestration of dlt pipelines.

# The Data Engineering Trinity: dlt, dbt, and Dagster

## Tool details

### dlt (data load tool)
- Core purpose: Extraction and loading tool that handles ingestion from various sources to destinations. Pipelines defined in `prometheus/dlt/`.
- Key concepts: Sources, resources, pipelines, normalization
- Best practices:
  - Schema handling and evolution
  - Authentication and credentials management
  - Incremental loading patterns
  - Error handling and retries
  - Pagination and rate limiting

### dbt (data build tool)
- Core purpose: Transformation layer using SQL models to transform raw data within the `transforms/` directory.
- Key concepts: Models, materializations, macros, tests
- Best practices:
  - Model organization and naming conventions
  - Testing strategies
  - Documentation
  - Incremental models
  - Optimizing for performance
  - Common SQL patterns

### Dagster
- Core purpose: Orchestration of data pipelines defined as assets within the `prometheus/` package, including triggering dlt and dbt runs.
- Key concepts: Assets, ops, jobs, schedules, sensors
- Best practices:
  - Asset-based orchestration
  - Testing and development workflow
  - Monitoring and observability
  - Partitioning
  - Integration with the other tools

## Project Structure Overview

Besides the core tool directories (`transforms/`, `prometheus/`), the project includes:

- Configuration files: `pyproject.toml`, `dagster.yaml`, `dagster_cloud.yaml`, `config.yaml`.
- Infrastructure definition: `Dockerfile`, `docker-compose.dev.yml`.
- Testing: `tests/` directory.
- CI/CD: `.github/` workflows.
- Development utilities: `scripts/`.
- Documentation: `docs/`.
- Development journal: `.dev/journal/`.

The combination of dlt (data load tool), dbt (data build tool), and Dagster creates a powerful, maintainable data stack that handles the complete lifecycle of data engineering projects. 

When used correctly, the combination of dlt, dbt, and Dagster creates a maintainable, testable, and observable data pipeline architecture. By focusing on incremental loading, modular transformations, and explicit dependencies, you'll build data systems that can evolve with your organization's needs.

Remember that the most elegant data engineering solutions are often the simplest ones. Don't over-engineer. Start small, test thoroughly, and expand methodically.
