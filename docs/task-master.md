# Using the claude-task-master Tool

1. Tool Identification:

Name: claude-task-master

Source: Python library available at https://github.com/eyaltoledano/claude-task-master

2. Purpose:

The claude-task-master tool automates the execution of complex, multi-step tasks.

It works by taking a high-level goal, breaking it down into a sequence of smaller, manageable sub-tasks, and then using an LLM (like Claude) to execute each sub-task sequentially.

Crucially, the output or result from one sub-task is used as context or input for the next sub-task, creating a chain of execution.

3. Core Concept:

Task Decomposition: An initial LLM call analyzes the main goal and generates a numbered list of sub-tasks required to achieve it.

Sequential Execution: The tool iterates through the generated sub-tasks one by one.

Context Preservation: For each sub-task execution, the LLM is provided with the original goal, the specific sub-task instruction, and the accumulated results from all previous sub-tasks. This maintains context throughout the process.

Final Consolidation: After all sub-tasks are completed, their results are often combined (based on the internal prompts) into a final, comprehensive output.

4. Prerequisites for Use:

Installation: The tool needs to be available in the execution environment. This typically involves:

Cloning the repository: git clone https://github.com/eyaltoledano/claude-task-master.git

Navigating into the directory: cd claude-task-master

Installing dependencies: pip install -r requirements.txt

API Key: An Anthropic API key is required. It must be configured, usually by setting the ANTHROPIC_API_KEY environment variable.

Python Environment: A Python environment capable of running the scripts and installed dependencies.

5. How to Use (Operational Steps):

Step 1: Import the TaskMaster Class:

from taskmaster import TaskMaster


Step 2: Define the Main Goal:

Specify the overall objective you want the tool to accomplish as a clear, descriptive string.

main_goal = "Write a comprehensive guide on setting up a basic Python development environment on Ubuntu, including installing Python, pip, venv, and Git."
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

Step 3: Instantiate TaskMaster:

Create an instance of the TaskMaster class, passing the goal as an argument.

You can optionally specify the model_name (e.g., "claude-3-opus-20240229") if you want to use a specific model, otherwise it might use a default defined in the configuration.

# Ensure ANTHROPIC_API_KEY environment variable is set before this
task_master = TaskMaster(goal=main_goal)
# Or with a specific model:
# task_master = TaskMaster(goal=main_goal, model_name="claude-3-sonnet-20240229")
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

Step 4: Run the Task Execution:

Call the .run() method on the TaskMaster instance. This initiates the entire process: task breakdown followed by sequential execution of sub-tasks.

The method returns the final consolidated result.

print("Executing task...")
final_result = task_master.run()
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

Step 5: Utilize the Result:

The final_result variable now holds the complete output generated by the tool after processing all sub-tasks.

print("\n--- Final Result ---")
print(final_result)
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

6. Key Inputs:

goal (string): The primary, high-level task description provided during TaskMaster instantiation. This is the most critical input.

model_name (string, optional): Specifies which Anthropic model to use.

ANTHROPIC_API_KEY (environment variable): Authentication credential for the Anthropic API.

7. Key Outputs:

Return Value of .run(): A string containing the final, consolidated result of executing all sub-tasks.

Console Output (Logging): During execution, the tool typically prints:

The generated list of sub-tasks.

The current sub-task being executed.

The result obtained for each sub-task.

8. Internal LLM Interactions (How You Participate as an LLM):

The TaskMaster tool will make multiple calls to the configured LLM (e.g., Claude).

Call 1 (Task Breakdown): You'll receive the main_goal and a system prompt asking you to break it down into logical, sequential steps. Your output should be a list of these steps.

Call 2 to N+1 (Sub-task Execution): For each sub-task identified in the breakdown:

You'll receive a prompt containing:

The original main_goal.

The specific instruction for the current sub-task.

The accumulated results from all previously completed sub-tasks.

A system prompt guiding you to execute only the current sub-task, using the provided context.

Your output should be the result of performing that single sub-task.

9. When to Use This Tool:

Use this tool when a request involves multiple distinct steps or requires building upon previous information.

Examples: Researching a topic then summarizing it, writing code based on specifications then testing it, drafting an outline then writing content for each section.

It's effective for tasks too complex or long for a single LLM prompt/response cycle.

10. Limitations & Considerations:

Dependency on Breakdown Quality: The overall success heavily depends on the LLM's ability to create a correct and logical task breakdown in the first step.

Error Propagation: An error or poor result in an early sub-task can negatively impact subsequent steps.

API Costs: Multiple LLM calls are made, which can increase API usage costs.

No Real-World Interaction (by default): The base tool orchestrates LLM calls. It doesn't inherently browse the web, run code (unless the LLM generates runnable code as output), or interact with external systems unless specifically designed/modified to do so.

This guide provides the necessary information for an LLM to understand what the claude-task-master tool is, how it works conceptually, and the specific steps required to operate it programmatically.